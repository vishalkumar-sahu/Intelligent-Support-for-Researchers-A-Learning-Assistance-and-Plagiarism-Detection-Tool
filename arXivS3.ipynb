{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishalkumar-sahu/Intelligent-Support-for-Researchers-A-Learning-Assistance-and-Plagiarism-Detection-Tool/blob/main/arXivS3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ5DZhHlVW4V"
      },
      "source": [
        "# **Working with ArXiv dataset with AWS S3 bucket --:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Irl4HiN3Vj0L"
      },
      "source": [
        "## **Installing aws cli --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qopVohuccXpl",
        "outputId": "8159fce2-ce0a-4264-984d-8c7a40cf409e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting awscli\n",
            "  Downloading awscli-1.29.3-py3-none-any.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore==1.31.3 (from awscli)\n",
            "  Downloading botocore-1.31.3-py3-none-any.whl (11.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: docutils<0.17,>=0.10 in /usr/local/lib/python3.10/dist-packages (from awscli) (0.16)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from awscli)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML<5.5,>=3.10 (from awscli)\n",
            "  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorama<0.4.5,>=0.2.5 (from awscli)\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting rsa<4.8,>=3.1.2 (from awscli)\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore==1.31.3->awscli)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.31.3->awscli) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore==1.31.3->awscli) (1.26.16)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.31.3->awscli) (1.16.0)\n",
            "Building wheels for collected packages: PyYAML\n",
            "  Building wheel for PyYAML (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.4.1-cp310-cp310-linux_x86_64.whl size=45658 sha256=c1c722af017a80b7fcf83585f1fc58108465ea09146ed1c5c560fa5092429b02\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/0d/22/696ee92245ad710f506eee79bb05c740d8abccd3ecdb778683\n",
            "Successfully built PyYAML\n",
            "Installing collected packages: rsa, PyYAML, jmespath, colorama, botocore, s3transfer, awscli\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "Successfully installed PyYAML-5.4.1 awscli-1.29.3 botocore-1.31.3 colorama-0.4.4 jmespath-1.0.1 rsa-4.7.2 s3transfer-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install awscli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NIQK_vWhPEp"
      },
      "outputs": [],
      "source": [
        "!mkdir config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsDnifFHVobr"
      },
      "source": [
        "## **Setting up credentials for AWS S3 bucket --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJTRtS5ofyox",
        "outputId": "02d07e59-6e50-4f95-a6db-a8b078c96ba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[default]\n",
            "aws_access_key_id = AKIAUFNH6K2XUE2ZPT4I\n",
            "aws_secret_access_key = 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\n",
            "region = us-east-1\n"
          ]
        }
      ],
      "source": [
        "text = '''\n",
        "[default]\n",
        "aws_access_key_id = ENTER_ACCESS_KEY\n",
        "aws_secret_access_key = ENTER_AWS_SECRET_KEY\n",
        "region = us-east-1\n",
        "'''\n",
        "path = \"/content/config/awscli.ini\"\n",
        "with open(path, 'w') as f:\n",
        "   f.write(text)\n",
        "!cat /content/config/awscli.ini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh9MEsPzWEJm"
      },
      "source": [
        "## **Setting up aws cli environment --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ysl5o9phVef",
        "outputId": "62269856-73ae-4a07-f4dd-03d1b9b044e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/config/awscli.ini\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!export AWS_SHARED_CREDENTIALS_FILE=/content/config/awscli.ini\n",
        "path = \"/content/config/awscli.ini\"\n",
        "os.environ['AWS_SHARED_CREDENTIALS_FILE'] = path\n",
        "print(os.environ['AWS_SHARED_CREDENTIALS_FILE'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUkdf4sRWNty"
      },
      "source": [
        "## **Downloading Manifest file --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkzwxNV_hhal",
        "outputId": "36f61638-1654-4aaf-91de-55ffe0c3d58d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed 256.0 KiB/2.5 MiB (628.1 KiB/s) with 1 file(s) remaining\rCompleted 512.0 KiB/2.5 MiB (1.2 MiB/s) with 1 file(s) remaining  \rCompleted 768.0 KiB/2.5 MiB (1.7 MiB/s) with 1 file(s) remaining  \rCompleted 1.0 MiB/2.5 MiB (2.3 MiB/s) with 1 file(s) remaining    \rCompleted 1.2 MiB/2.5 MiB (2.7 MiB/s) with 1 file(s) remaining    \rCompleted 1.5 MiB/2.5 MiB (3.2 MiB/s) with 1 file(s) remaining    \rCompleted 1.8 MiB/2.5 MiB (3.7 MiB/s) with 1 file(s) remaining    \rCompleted 2.0 MiB/2.5 MiB (4.3 MiB/s) with 1 file(s) remaining    \rCompleted 2.2 MiB/2.5 MiB (4.8 MiB/s) with 1 file(s) remaining    \rCompleted 2.5 MiB/2.5 MiB (5.1 MiB/s) with 1 file(s) remaining    \rCompleted 2.5 MiB/2.5 MiB (5.1 MiB/s) with 1 file(s) remaining    \rdownload: s3://arxiv/pdf/arXiv_pdf_manifest.xml to data/arXiv_pdf_manifest.xml\n"
          ]
        }
      ],
      "source": [
        "!aws s3 cp --request-payer requester s3://arxiv/pdf/arXiv_pdf_manifest.xml /content/data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35d9jTeHWjcY"
      },
      "source": [
        "## **Printing metadata from manifest file --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kKoURniAiHW"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Path to your XML file\n",
        "xml_file_path = '/content/data/arXiv_pdf_manifest.xml'\n",
        "\n",
        "# Parse the XML file\n",
        "tree = ET.parse(xml_file_path)\n",
        "root = tree.getroot()\n",
        "\n",
        "# Access and process the XML data\n",
        "for file_elem in root.findall('file'):\n",
        "    content_md5sum = file_elem.find('content_md5sum').text\n",
        "    filename = file_elem.find('filename').text\n",
        "    first_item = file_elem.find('first_item').text\n",
        "    last_item = file_elem.find('last_item').text\n",
        "    md5sum = file_elem.find('md5sum').text\n",
        "    num_items = file_elem.find('num_items').text\n",
        "    seq_num = file_elem.find('seq_num').text\n",
        "    size = file_elem.find('size').text\n",
        "    timestamp = file_elem.find('timestamp').text\n",
        "    yymm = file_elem.find('yymm').text\n",
        "\n",
        "    # Process the data or perform any required operations\n",
        "    print('Filename:', filename)\n",
        "    print('First Item:', first_item)\n",
        "    print('Last Item:', last_item)\n",
        "    print('Number of Items:', num_items)\n",
        "    print('Sequence Number:', seq_num)\n",
        "    print('Size:', size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa2NhkRxWz_s"
      },
      "source": [
        "## **Getting the Numbers of file available in ArXiv S3 bucket --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaJwarf9LIYN",
        "outputId": "a3651d9f-f899-463a-e122-bd852904d69e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of tar files: 6233\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Path to your XML file\n",
        "xml_file_path = '/content/data/arXiv_pdf_manifest.xml'\n",
        "\n",
        "# Parse the XML file\n",
        "tree = ET.parse(xml_file_path)\n",
        "root = tree.getroot()\n",
        "\n",
        "# Count the number of tar files\n",
        "tar_file_count = 0\n",
        "\n",
        "# Iterate over each <file> element in the XML\n",
        "for file_elem in root.findall('file'):\n",
        "    filename = file_elem.find('filename').text\n",
        "\n",
        "    # Check if the file is a tar file\n",
        "    if filename.endswith('.tar'):\n",
        "        tar_file_count += 1\n",
        "\n",
        "print('Number of tar files:', tar_file_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjiLF0_OXOYM"
      },
      "source": [
        "## **Downloading TAR files from S3 bucket --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wkd25I5xLOch",
        "outputId": "951010b5-a17e-4e90-fd51-6d4bd98801c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded: pdf/arXiv_pdf_0001_001.tar\n",
            "Downloaded: pdf/arXiv_pdf_0001_002.tar\n",
            "Finished\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import subprocess\n",
        "\n",
        "# Path to your XML file\n",
        "xml_file_path = '/content/data/arXiv_pdf_manifest.xml'\n",
        "\n",
        "# Parse the XML file\n",
        "tree = ET.parse(xml_file_path)\n",
        "root = tree.getroot()\n",
        "\n",
        "# Download PDF files from arXiv S3 bucket\n",
        "def download_file(fname, out_dir):\n",
        "    cmd = ['aws', 's3', 'cp', '--request-payer', 'requester',\n",
        "           's3://arxiv/%s' % fname, './%s' % out_dir]\n",
        "    subprocess.call(cmd)\n",
        "\n",
        "output_dir = '/data/dataset/'\n",
        "\n",
        "# Iterate over each <file> element in the XML\n",
        "count = 0\n",
        "for file_elem in root.findall('file'):\n",
        "    filename = file_elem.find('filename').text\n",
        "\n",
        "    # Download the PDF file\n",
        "    download_file(filename, output_dir)\n",
        "\n",
        "    # Print the filename for logging\n",
        "    print('Downloaded:', filename)\n",
        "\n",
        "    count += 1\n",
        "    if count == 2:\n",
        "      break\n",
        "\n",
        "print('Finished')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEzLv4ztX88H"
      },
      "source": [
        "## **Extracting the Pdf files from TAR files--**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmyFeF1xYAn4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tarfile\n",
        "\n",
        "def extract_tarfile(file_path, destination_path):\n",
        "    with tarfile.open(file_path, 'r') as tar:\n",
        "        tar.extractall(destination_path)\n",
        "\n",
        "def extract_all_tarfiles(folder_path, destination_path):\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        if file_name.endswith('.tar'):\n",
        "            extract_tarfile(file_path, destination_path)\n",
        "\n",
        "# Example usage\n",
        "folder_path = '/content/data/dataset'\n",
        "destination_path = '/content/data/pdf'\n",
        "extract_all_tarfiles(folder_path, destination_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8_QXRwnY0Ko"
      },
      "source": [
        "## **Installing dependencies and importing it --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqFKOlZjhjrC",
        "outputId": "f843c6c5-9dbe-4c9d-f367-1c5971ebb017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting embeddings\n",
            "  Downloading embeddings-0.0.8-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from embeddings) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from embeddings) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from embeddings) (1.22.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->embeddings) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->embeddings) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->embeddings) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->embeddings) (3.4)\n",
            "Installing collected packages: embeddings\n",
            "Successfully installed embeddings-0.0.8\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-3.12.1-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.8/254.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.12.1\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence_transformers)\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence_transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence_transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=9d4f3ca76f40b3a4300191e8dc95ed9adaca7f609f563c4389299b241587b29c\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, huggingface-hub, transformers, sentence_transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 sentence_transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.30.2\n",
            "Collecting ray\n",
            "  Downloading ray-2.5.1-cp310-cp310-manylinux2014_x86_64.whl (56.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from ray) (23.1.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.12.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (23.1)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (5.4.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.27.1)\n",
            "Collecting grpcio<=1.51.3,>=1.42.0 (from ray)\n",
            "  Downloading grpcio-1.51.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from ray) (1.22.4)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.19.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.4)\n",
            "Installing collected packages: grpcio, ray\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.56.0\n",
            "    Uninstalling grpcio-1.56.0:\n",
            "      Successfully uninstalled grpcio-1.56.0\n",
            "Successfully installed grpcio-1.51.3 ray-2.5.1\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain\n",
        "!pip install embeddings\n",
        "!pip install pypdf\n",
        "!pip install sentence_transformers\n",
        "!pip install ray\n",
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiCdn3mS2_Nf"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.base import Embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "\n",
        "from typing import List\n",
        "import time\n",
        "import os\n",
        "import ray\n",
        "import numpy as np\n",
        "import pypdf\n",
        "from urllib.error import HTTPError\n",
        "import requests\n",
        "import subprocess\n",
        "import shutil\n",
        "from time import sleep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQaTbGbNJ7L_"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcNf-UrSY7VX"
      },
      "source": [
        "## **Initializing Ray Instance --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "I6y_Ra7xjm-A",
        "outputId": "2b60ee27-57dc-4982-f77a-e2706d4b1268"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-15 09:07:12,035\tINFO worker.py:1636 -- Started a local Ray instance.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
              "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
              "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
              "            <g id=\"layer-1\">\n",
              "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
              "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
              "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
              "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
              "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
              "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
              "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
              "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
              "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
              "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
              "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
              "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
              "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
              "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
              "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
              "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
              "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
              "            </g>\n",
              "        </svg>\n",
              "        <table>\n",
              "            <tr>\n",
              "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
              "                <td style=\"text-align: left\"><b>3.10.12</b></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
              "                <td style=\"text-align: left\"><b> 2.5.1</b></td>\n",
              "            </tr>\n",
              "            \n",
              "        </table>\n",
              "    </div>\n",
              "</div>\n"
            ],
            "text/plain": [
              "RayContext(dashboard_url='', python_version='3.10.12', ray_version='2.5.1', ray_commit='a03efd9931128d387649dd48b0e4864b43d3bfb4', address_info={'node_ip_address': '172.28.0.12', 'raylet_ip_address': '172.28.0.12', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-07-15_09-07-09_333835_517/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-07-15_09-07-09_333835_517/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2023-07-15_09-07-09_333835_517', 'metrics_export_port': 62008, 'gcs_address': '172.28.0.12:51394', 'address': '172.28.0.12:51394', 'dashboard_agent_listen_port': 52365, 'node_id': '0fcdb45fe644c9e71726d3faa56039aef4fb38782d46b1df92926b0f'})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ray.shutdown()\n",
        "ray.init(num_cpus = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzv1ny8YZBES"
      },
      "source": [
        "## **Loading the Pdfs from the folder using PyPDFLoader --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGWgj9Yxhy0N",
        "outputId": "8cd510cb-be76-4452-b401-ea369bb52318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/data/pdf/0001\n"
          ]
        }
      ],
      "source": [
        "folder_path = '/content/data/pdf'\n",
        "\n",
        "pdf_loaders = []\n",
        "\n",
        "for folder_name in os.listdir(folder_path):\n",
        "    path = os.path.join(folder_path, folder_name)\n",
        "    print(path)\n",
        "    for filename in os.listdir(path):\n",
        "      if filename.endswith('.pdf'):\n",
        "        file_path = os.path.join(path, filename)\n",
        "        pdf_loaders.append(PyPDFLoader(file_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiXQ-8WS60Zh",
        "outputId": "4f22c50c-5a1b-46b7-ba3a-1a651476e25a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2345\n"
          ]
        }
      ],
      "source": [
        "print(len(pdf_loaders))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3REjbnaUaLpt"
      },
      "source": [
        "## **Extracting pdfs and dividing text into chunks --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "666gYsqQwyAa",
        "outputId": "7fafe113-a482-48e9-f1a5-b8282b29658b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "350021\n"
          ]
        }
      ],
      "source": [
        "docs = []\n",
        "for i in range(len(pdf_loaders)):\n",
        "    try :\n",
        "      docs.extend(pdf_loaders[i].load_and_split())\n",
        "    except Exception as e:\n",
        "      continue\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 300,\n",
        "    chunk_overlap = 20,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "chunks = text_splitter.create_documents(\n",
        "    [doc.page_content for doc in docs],\n",
        "    metadatas=[doc.metadata for doc in docs])\n",
        "\n",
        "print(len(chunks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_05TZfov3Rjo",
        "outputId": "10d59be1-49dd-4b0a-cc1c-bc0c2d1de798"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='advantage of being very parsimonious. This  will be relaxed if future investigations as there is' metadata={'source': '/content/data/pdf/0001/cond-mat0001425.pdf', 'page': 39}\n"
          ]
        }
      ],
      "source": [
        "print(chunks[100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkd8fps3aPm6"
      },
      "source": [
        "## **Initializing the FAISS Vector Database --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0f9r8bMQUiS"
      },
      "outputs": [],
      "source": [
        "FAISS_INDEX_PATH = \"faiss_index_09062023\"\n",
        "\n",
        "class LocalHuggingFaceEmbeddings(Embeddings):\n",
        "    def __init__(self, model_id):\n",
        "        self.model = SentenceTransformer(model_id)\n",
        "\n",
        "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
        "        embeddings = self.model.encode(texts)\n",
        "        return embeddings\n",
        "\n",
        "    def embed_query(self, text: str) -> List[float]:\n",
        "        embedding = self.model.encode(text)\n",
        "        return list(map(float, embedding))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZLECoRTaUwE"
      },
      "source": [
        "## **Function for creating Embeddings --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43jXhtZIQKMX"
      },
      "outputs": [],
      "source": [
        "@ray.remote(num_gpus=0.5)\n",
        "def process_shard(shard):\n",
        "    print(f\"Starting process_shard of {len(shard)} chunks.\")\n",
        "    st = time.time()\n",
        "\n",
        "    embeddings = LocalHuggingFaceEmbeddings(\"multi-qa-mpnet-base-dot-v1\")\n",
        "    result = FAISS.from_documents(shard, embeddings)\n",
        "\n",
        "    et = time.time() - st\n",
        "    print(f\"Shard completed in {et} seconds.\")\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1L2Jpn4kLgN",
        "outputId": "d87c69da-8913-4640-c6af-f6feab26bcee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======== Autoscaler status: 2023-07-15 10:04:48.388632 ========\n",
            "Node status\n",
            "---------------------------------------------------------------\n",
            "Healthy:\n",
            " 1 node_0fcdb45fe644c9e71726d3faa56039aef4fb38782d46b1df92926b0f\n",
            "Pending:\n",
            " (no pending nodes)\n",
            "Recent failures:\n",
            " (no failures)\n",
            "\n",
            "Resources\n",
            "---------------------------------------------------------------\n",
            "Usage:\n",
            " 0.0/1.0 CPU\n",
            " 0.0/1.0 GPU\n",
            " 0B/7.33GiB memory\n",
            " 0B/3.66GiB object_store_memory\n",
            "\n",
            "Demands:\n",
            " (no resource demands)\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! ray status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LAgNHgKab76"
      },
      "source": [
        "## **Creating Embeddings --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yUziVybQLRh",
        "outputId": "b25f254b-b9eb-4382-9ebd-ec8ab555743a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(process_shard pid=16535)\u001b[0m Starting process_shard of 175011 chunks.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading (…)16ebc/.gitattributes: 100%|██████████| 737/737 [00:00<00:00, 4.71MB/s]\n",
            "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 960kB/s]\n",
            "Downloading (…)b6b5d16ebc/README.md: 100%|██████████| 8.65k/8.65k [00:00<00:00, 26.0MB/s]\n",
            "Downloading (…)b5d16ebc/config.json: 100%|██████████| 571/571 [00:00<00:00, 3.01MB/s]\n",
            "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 778kB/s]\n",
            "Downloading (…)ebc/data_config.json: 100%|██████████| 25.5k/25.5k [00:00<00:00, 24.6MB/s]\n",
            "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]\n",
            "Downloading pytorch_model.bin:   5%|▍         | 21.0M/438M [00:00<00:02, 146MB/s]\n",
            "Downloading pytorch_model.bin:  12%|█▏        | 52.4M/438M [00:00<00:01, 197MB/s]\n",
            "Downloading pytorch_model.bin:  19%|█▉        | 83.9M/438M [00:00<00:01, 212MB/s]\n",
            "Downloading pytorch_model.bin:  26%|██▋       | 115M/438M [00:00<00:01, 219MB/s] \n",
            "Downloading pytorch_model.bin:  34%|███▎      | 147M/438M [00:00<00:01, 220MB/s]\n",
            "Downloading pytorch_model.bin:  41%|████      | 178M/438M [00:00<00:01, 217MB/s]\n",
            "Downloading pytorch_model.bin:  48%|████▊     | 210M/438M [00:00<00:01, 219MB/s]\n",
            "Downloading pytorch_model.bin:  55%|█████▌    | 241M/438M [00:01<00:00, 218MB/s]\n",
            "Downloading pytorch_model.bin:  62%|██████▏   | 273M/438M [00:01<00:00, 220MB/s]\n",
            "Downloading pytorch_model.bin:  69%|██████▉   | 304M/438M [00:01<00:00, 212MB/s]\n",
            "Downloading pytorch_model.bin:  77%|███████▋  | 336M/438M [00:01<00:00, 210MB/s]\n",
            "Downloading pytorch_model.bin:  84%|████████▍ | 367M/438M [00:01<00:00, 209MB/s]\n",
            "Downloading pytorch_model.bin:  91%|█████████ | 398M/438M [00:01<00:00, 215MB/s]\n",
            "Downloading pytorch_model.bin: 100%|██████████| 438M/438M [00:02<00:00, 213MB/s]\n",
            "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 353kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 1.73MB/s]\n",
            "Downloading (…)16ebc/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]\n",
            "Downloading (…)16ebc/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 9.25MB/s]\n",
            "Downloading (…)okenizer_config.json: 100%|██████████| 363/363 [00:00<00:00, 2.93MB/s]\n",
            "Downloading (…)6ebc/train_script.py: 100%|██████████| 13.9k/13.9k [00:00<00:00, 64.8MB/s]\n",
            "Downloading (…)b6b5d16ebc/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 9.53MB/s]\n",
            "Downloading (…)5d16ebc/modules.json: 100%|██████████| 229/229 [00:00<00:00, 1.47MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(process_shard pid=16535)\u001b[0m Shard completed in 1837.3609502315521 seconds.\n",
            "\u001b[2m\u001b[36m(process_shard pid=24588)\u001b[0m Starting process_shard of 175010 chunks.\n",
            "\u001b[2m\u001b[36m(process_shard pid=24588)\u001b[0m Shard completed in 1799.8726999759674 seconds.\n"
          ]
        }
      ],
      "source": [
        "core = 2\n",
        "shards = np.array_split(chunks, core)\n",
        "\n",
        "futures = [process_shard.remote(shards[i]) for i in range(core)]\n",
        "results = ray.get(futures)\n",
        "\n",
        "db = results[0]\n",
        "for i in range(1, core):\n",
        "    db.merge_from(results[i])\n",
        "\n",
        "db.save_local(FAISS_INDEX_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3KNbnuhskS7m",
        "outputId": "1f8d4dd4-ab73-458d-bd11-2c1653540015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======== Autoscaler status: 2023-07-15 11:06:45.148707 ========\n",
            "Node status\n",
            "---------------------------------------------------------------\n",
            "Healthy:\n",
            " 1 node_0fcdb45fe644c9e71726d3faa56039aef4fb38782d46b1df92926b0f\n",
            "Pending:\n",
            " (no pending nodes)\n",
            "Recent failures:\n",
            " (no failures)\n",
            "\n",
            "Resources\n",
            "---------------------------------------------------------------\n",
            "Usage:\n",
            " 0.0/1.0 CPU\n",
            " 0.0/1.0 GPU\n",
            " 0B/7.33GiB memory\n",
            " 2.06GiB/3.66GiB object_store_memory\n",
            "\n",
            "Demands:\n",
            " (no resource demands)\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! ray status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvNKy9zdagOn"
      },
      "source": [
        "## **Shutdown RAY Instance --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Bqb9RU4-X1If"
      },
      "outputs": [],
      "source": [
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVTjgspVamRo"
      },
      "source": [
        "## **Installing Necessary Dependencies and importing it --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "deDVYmuAg6j7",
        "outputId": "9896f690-cbc2-480b-ab48-c0bf59fa99d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UjRp10mZg95R"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viri3ksqaqUS"
      },
      "source": [
        "## **Setting up OPENAI Cerenditals --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mOGVT35hAyj"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
        "llm = OpenAI(openai_api_key=\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjQqBpdQauEd"
      },
      "source": [
        "## **Initializing the Buffer Memory --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eMVCCHRhLop"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "pdf_qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0.9) , db.as_retriever(), memory=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkWnzV0jax1s"
      },
      "source": [
        "## **Answering the Questions --**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "iqs5g04Okz2Q",
        "outputId": "fb90a672-9f38-4a98-a6b4-fd7e769b5c96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The main focus of the paper is to explore the possible effects of the tachocline on solar evolution.'"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What is the main focus of the paper Influence of the tachocline on solar evolution by A. S. Brun and J.-P. Zahn?\"\n",
        "result = pdf_qa({\"question\": query})\n",
        "print(\"Answer:\")\n",
        "result[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "SVjdUWHspdph",
        "outputId": "396a7610-4364-496f-83e5-4a043e5a05a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The theoretical techniques used to study the electron-phonon interaction in C70 included a model and numerical calculations. The experimental techniques used were those discussed in N. David Mermin (Saunders College, 1976), D.P. Young et al., Nature 397 (1999), R. L. Powell et al., Jnl. Appl. Phys. 28 (1957), and R. Berman and D.K.C. MacDonald, Proc. Roy. Soc. Lon. (1957).'"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What theoretical and experimental techniques were employed in the study of electron-phonon interaction in C70?\"\n",
        "result = pdf_qa({\"question\": query})\n",
        "print(\"Answer:\")\n",
        "result[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "aO3sC-rNprsC",
        "outputId": "f9eac654-38fa-47dd-e0f0-e5185ec4ec9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The magnetoconductivity measurements of the icosahedral and amorphous films can be described by nearly the same set of parameters if the samples are of identical composition.'"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"How do the magnetoconductivity measurements of the icosahedral and amorphous films compare at different temperatures and magnetic fields?\"\n",
        "result = pdf_qa({\"question\": query})\n",
        "print(\"Answer:\")\n",
        "result[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "M_Xxv-PGKEqB",
        "outputId": "ea04c2fd-dae8-45f2-d7b3-194e45b787aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The fitting parameters used to analyze the magnetoconductivity data of icosahedral and amorphous films are WL and EEI contributions. For metallic films, the WL and EEI contributions can be used to obtain a good fit, while for insulating films, the WL and EEI contributions can be used to fit a simple power law.'"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What fitting parameters are used to analyze the magnetoconductivity data, and how do they differ between the metallic and insulating films?\"\n",
        "result = pdf_qa({\"question\": query})\n",
        "print(\"Answer:\")\n",
        "result[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "FJOFc6r6KPFM",
        "outputId": "53115495-23e8-4ebf-e3bd-8d79e3f1d645"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-AFzG9Y08iLEbV1WBBRObDwa4 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The zero field conductivity data of the metallic icosahedral film can be described by WL and EEI theories if the film is well on the metallic side of the metal-insulator transition, and the WL theory breaks down already in the vicinity of the MIT.'"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"How does the zero field conductivity of the metallic icosahedral film compare with the WL and EEI contributions determined from the magnetoconductivity data?\"\n",
        "result = pdf_qa({\"question\": query})\n",
        "print(\"Answer:\")\n",
        "result[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "serZKmgsK_N9",
        "outputId": "57282aa4-9328-4f62-901a-f6bef80d7326"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Research has been done related to algorithms that introduce a congestion window mechanism to control the number of bytes a sender can transmit before waiting for an acknowledgment, such as those described in [3] M. Mathis, J. Semske, J. Mahdavi and T. Ott, “The macroscopic behavior of the TCP congestion avoidance algorithm”, Computer Communication Review , vol. 27 n. 3, pp 67-82, July 1997 and [4] W. Stevens, \"TCP Slow Start, Congestion Avoidance, Fast Retransmit, and Fast Recovery Algorithms\", RFC 2001, January 1997.'"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"Provide details of research that have information regarding algorithm that 'introduces a congestion window mechanism to control the number of bytes that the sender is able to transmit before waiting for an acknowledgment.' ?\"\n",
        "result = pdf_qa({\"question\": query})\n",
        "print(\"Answer:\")\n",
        "result[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMIlfBnvTDFh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
